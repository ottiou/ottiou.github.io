---
layout: post
title:  "神经结构搜索(NAS)：概述"
date:   2019-05-02 23:50:55 +0800
categories: AI
---
# 神经结构搜索：概述

## 摘要

近些年来，深度学习在图像识别、语音识别和机器翻译等领域飞速发展并取得了显著成果。这些新进展的一个关键因素在于新的神经架构。现在大多的架构是由人类专家手工开发的，这是一个耗时且容易出错的过程。正因如此，人们渐渐有了自动神经架构搜索的想法。本文概述了这一研究领域的现有工作，并根据搜索空间、搜索策略和性能评估策略三个维度进行分类。 

## 1.简介

在感知任务中深度学习的成功很大程度上归功于其对于特征工程过程的自动化即：分层特征提取器从数据中以end-to-end的方式学习而不是手动设计。然而，随着对结构工程需求的不断增长，这种成功也需要手动设计更加复杂的神经架构。神经架构搜索(NAS)是自动架构工程的过程，因此很自然是机器学习自动化的下一步。目前为止，NAS方法在某些任务上表现优于手工设计的架构，如图像分类(Zoph等，2018;Real等，2019)，物体检测（Zoph等，2018）或语义分割（Chen等，2018）。NAS可以被视为AutoML的子领域（Hutter等，2019），并且与超参数优化（Feurer和Hutter，2019）和meta-learning（Vanschoren，2019）明显具有重叠。我们根据三个维度对NAS的方法进行分类：搜索空间，搜索策略和性能评估策略：


- **搜索空间.**
搜索空间定义了原则上可以表示哪些体系结构。结合适合任务架构的典型特征的先验知识可以减小搜索空间的大小并简化搜索。然而，这也引入了人为偏见，这可能会阻止找到超越当前人类知识的新颖结构构建模块。

- **搜索策略.**
搜索策略详细说明了如何探索搜索空间（通常是指数阶增大甚至是无界的）。因为一方面需要快速找到性能良好的架构，另一方面还应避免过早收敛到次优架构区域，故搜索策略包含了经典的探索和择优的权衡。

- **性能评估策略.**
NAS的目标通常是能够在不可视数据上实现找到高预测性能的结构。*性能评估*是指评估此性能的过程：最简单的选择是对数据结构执行标准培训和验证，但遗憾的是计算成本很高，并且可探索结构的数量有限制的。因此，最近的许多研究都集中在开发降低这些性能估计成本的方法。


我们参考下图来举例说明。文章也是根据这三个维度：下面的三部分分别是搜索空间、搜索策略和性能评估策略。最后，展望未来的研究方向。神经结构搜索方法的抽象插图。按搜索策略从预定义的搜索空间$ \mathcal{A} $中选择一个结构$ \mathsf{A} $。该结构被传递给性能估计策略，计算后后将$ \mathsf{A} $的评估性能返回到搜索策略。

![overview_figure](/overview_figure.jpg)
*神经结构搜索方法的抽象插图。按搜索策略从预定义的搜索空间$ \mathcal{A} $中选择一个结构$ \mathsf{A} $。该结构被传递给性能估计策略，计算后后将$ \mathsf{A} $的评估性能返回到搜索策略。*



## 搜索空间

搜索空间定义了NAS方法从原理上可能发现的神经架构。 现在本文讨论最近研究中常见的搜索空间。

一个相对简单的搜索空间是*链式神经网络*空间，如下图(左)所示。链式神经网络结构$ \mathsf{A} $可以写成$ n $层的序列，其中第i层$ L_i $从第$ i-1 $层接收输入，并且输出给第$ i + 1 $层，即，$\mathsf{A}= L_{n} \circ \dots L_{1} \circ L_{0} $。下面对搜索空间进行参数化： 
- (i)(最大)层数$ n $(可能无界);
- (ii)每层可能的操作类型，如池化、卷积或者更高级的操作像深度可分离卷积(Chollet 2016)、扩张卷积(Yu\&Koltun 2016)；
- (iii)操作相关的超参数，如过滤器数量，卷积核数和步长 (Baker等, 2017; Suganuma等, 2017; Cai等, 2018)，或者是完全连接网络的单元数量 (Mendoza等, 2016)。

 注意，(iii)中参数以(ii)为条件，因此搜索空间的参数化不是固定长度而是条件化空间。

 ![chain_mb_space_v2](/chain_mb_space_v2.jpg)
 *不同结构空间的插图。图中的每个节点对应于神经网络中的一个层，如卷积或者池化层。不同层的类型通过不同的颜色来区分。从$L_{i}$层到$L_{j}$层的边界表示$L_{j}$层接收$L_{i}$层的输出作为自己的输入。左:一个链式空间。右:一个更复杂的搜索空间，具有额外的层类型、多个分支以及跳跃式连接。*


最近对NAS的研究 (Brock等,2017; Elsken等,2017; Zoph等,2018; Elsken等,2019; Real等,2019;Cai等,2018b)融合了手工制作结构的现代设计，如跳跃式连接，这种方式可以构建复杂的、多分支的网络如上图(右)。这里第$ i $层输入可以基于前面各层输出形式上表示为函数$ g_i(L_{i-1} ^ {out}, \dots, L_{0}^ {out})$。使用这样的函数可以显著提高自由度。这些多分支结构的特殊情况是 
- (i) 链式网络(通过设置 $g_i(L_{i-1}^{out}, \dots , L_{0}^{out}) = L_{i-1}^{out}$)，
- (ii) 剩余网络(He等, 2016)，这种的输入是对前面层输出的求和即

$$g_i(L_{i-1}^{out}, \dots , L_{0}^{out}) = L_{i-1}^{out}+L_{j}^{out},\ j<i-1,$$

- (iii) DenseNets(Huang等,2017)，这种输入是与前面各层的输出相关联

$$g_i(L_{i-1}^{out}, \dots , L_{0}^{out}) = concat( L_{i-1}^{out}, \dots , L_{0}^{out}).$$

受手工制作结构的启发，应由重复的结构组成(Szegedy等,2016; He等,2016; Huang等,2017)，Zoph等(2018)和Zhong等(2018a)认为应搜索分别称为*cells*或*blocks*这样的结构，而不是整个结构。Zoph等(2018)优化两种不同的cell:一种是*正则cell*其保持输入的维数不变，另一种是*衰减cell*它的空间维数减少。然后通过规定方式堆叠这些cell来构建最终的结构，如下图。对比上面讨论，搜索空间主要有如下三个优点：
- 搜索空间的大小减少很多，因为组成cell的层通常比整个结构少很多。例如，Zoph等(2018)与之前的工作(Zoph和Le, 2017)相比大概加速了7倍，同时获得了更好的性能。
- 通过简单地修改模型中使用cell和过滤器的数量，可以容易地将由cell构建的结构转移或者适应于其他数据集。现实中，Zoph等(2018)将在CIFAR-10上优化的cell转移到ImageNet中并获得目前最先进的性能。
- 通过重复构造block创建的结构被证明通常是有用的设计原理，如在RNN中重复LSTM block或堆叠剩余block。

![cell_space](/cell_space.jpg)
*cell搜索空间图示。左: 两个不同cell，如：正则cell(上面)和剩余cell (下面)(Zoph等, 2018)。右:顺序堆叠cell构造的结构。注意cell也可以用更复杂的方式连接，如多分支空间中，用cell替换层。*

因此，近来基于cell的搜索空间在许多工作中成功运用(Real等, 2019; Liu等, 2018a; Pham等, 2018; Elsken等, 2019; Cai等, 2018b; Liu等, 2019b; Zhong等, 2018b)。然而，当使用基于cell的搜索空间时，会出现一种新的设计选择，即如何选择*宏观结构*：使用多少个cell以及如何连接它们来构造实际模型？例如：Zoph等(2018)使用cell构造顺序模型，即每个cell接收前两个cell的输出作为其输入；而Cai等(2018b)采用已知手工设计的高级结构，如DenseNet(Huang如，2017)，在这些模型中使用它们的cell。原理上，通过简单地用cell替换层可以任意组合cell，如在上述的多分支空间。理想情况下，宏观结构和微观结构(即cell结构)应该结合一起优化，而不是单独优化微观结构；否则，在找到性能良好的cell后，可能必须去手动构造宏观结构。Liu等(2018)提出的分层搜索空间迈出了优化宏观结构的重要一步，这样的空间包含多级结构。第一级包含一组原始操作，第二级包含通过有向无环图连接原始操作组成的不同结构，第三级是以某种方式连接第二级组成的结构，等等。cell搜索空间可被视为三级分层搜索空间的特殊情况，二级结构对应cell，三级是宏观结构的编码方式。


搜索空间的选择很大程度决定了优化问题的难度：即使对于基于固定宏观结构的单一cell搜索空间的情况，优化问题仍然是(i)非连续的和(ii)相对高维的(因为更复杂的模型往往表现更好，可以带来更多的设计选择)。


注意到许多搜索空间的结构可以写成固定长度的向量；如：Zoph等(2018)对于两个cell中每一个的搜索空间可以被写为40维[^footnote1]。具有分类维度的搜索空间，每个搜索空间在少量不同的构造block和输入之间进行选择。无界搜索空间可约束为(可能很大)有限层，这又产生具有(可能很多)条件维度固定大小的搜索空间。

在下一节中，将讨论适合这些搜索空间的搜索策略。


## 搜索策略

不同的搜索策略可用于探索神经结构空间，包括随机搜索，Bayesian优化，进化算法，强化学习（RL）和基于梯度的算法。从历史上，许多研究人员在几十年前已经使用进化算法发展神经结构(通常也有他们的权重) (如: Angeline等, 1994; Stanley和Miikkulainen, 2002; Floreano等, 2008; Stanley等, 2009; Jozefowicz等, 2015)。Yao(1999)提供了2000年之前工作文献的综述。


自2013年以来Bayesian优化在NAS中取得了一些早期成功，引领了最先进的视觉架构(Bergstra等，2013)，CIFAR-10无数据增强(Domhan等，2015)的最先进性能，以及第一个自动调谐神经网络在竞争数据集上战胜人类专家(Mendoza等，2016)。Zoph和Le(2017)通过基于强化学习的搜索策略在CIFAR-10和Penn Treebank基准测试获得有竞争力的表现后，NAS成为机器学习领域的主流研究课题。虽然Zoph和Le(2017)使用大量的计算资源来实现这一结果(800个GPU运行三到四周)，但在他们的工作之后，很快不断有各种各样的方法发布以降低计算成本并实现进一步的性能改进。

为了将NAS构建为*强化学习*RL)问题，可以将神经结构的生成视为agent动作，其中动作空间等同于搜索空间。agent的reward通过一个测试集上的效果预测函数来获得(参见性能评估策略部分)。不同的RL方法在agent的策略表示和算法优化方面有所不同：Zoph和Le(2017)使用递归神经网络(RNN)策略来顺序地对数据进行采样，然后生成对神经结构。他们最初使用强化梯度算法(Williams，1992)训练神经网络，但在他们的后续工作中(Zoph等，2018)使用Proximal策略进行优化(Schulman等，2017)。Baker等(2017a)使用Q-learning去训练依次选择层的类型和对应的超参数。


这些方法的另一种观点是顺序决策过程，其中策略采样action按顺序生成结构，环境的“状态”包含到目前采样action的概括，并且仅在最后的action包含(未打折扣的)reward。但是，由于在顺序过程中没有与环境的交互(没有考虑到外部状态，也没有中间reward)，故可以直观地将结构抽样过程解释为单个action顺序生成；这将RL问题简化为多臂老虎机(stateless multi-armed bandit)问题。

Cai等(2018a)提出了一种相关的方法，将NAS规定为一个顺序决策过程：此方法中，状态是当前(部分训练的)结构，reward是对结构性能的估计，并且action对应于保持变化函数的应用，称为网络态射(Chen等，2016;Wei等，2017)，另见性能评估策略部分，然后是网络的训练阶段。为了处理可变长度网络结构，使用双向LSTM将结构规定为固定长度表示。基于这种结构表示，参与网络决定了采样action。这两组件的组合构成了策略，该策略使用强化梯度算法进行end-to-end训练。注意到这种方法不会访问同一状态(结构)两次。



另一种使用RL方法是利用进化算法优化神经结构的*神经进化*算法。第一次用这种方法设计神经网络可以追溯到大概三十年前：Miller等(1989)用遗传算法提出结构并用反向传播来优化权重。自那开始，许多神经进化算法(Angeline等，1994；Stanley和Miikkulainen，2002；Stanley等，2009)使用遗传算法来优化神经结构和权重;然而，当代用于监督学习的神经架构已扩展到数百万个权重时，目前基于SGD的权重优化算法优于进化算法。[^footnote2]因此，最近的神经进化方法 (Real等, 2017; Suganuma等, 2017; Liu等, 2018b; Real等, 2019; Miikkulainen等, 2017; Xie和Yuille, 2017; Elsken等, 2019)再次使用基于梯度方法来优化权重，且仅使用进化算法来优化神经结构本身。进化算法演化出系列模型，即一个(可能是训练过的)网络集;在每个进化步骤中，至少对种群的一个模型进行采样，并且作为父母通过突变来生成子孙。在NAS中，突变是局部操作，如添加或移除一个层、改变层的超参数、添加跳跃式连接，或者改变训练的超参数。对后代进行训练之后，评估它们的适应性(例如，在测试集上的性能)并将它们添加到种群中。

神经进化算法在如何从父母采样、更新种群和产生后代方面有所不同。例如，Real等(2017)，Real等(2019)和Liu等(2018b)使用Tournament Selection(Goldberg和Deb，1991)对父母采样，而Elsken等(2019)使用使用反密度的多目标Pareto前沿对父母采样。Real等(2017)从群体中移除了最差的个体，而Real等(2019)发现移除最老的个体(减少贪心)和Liu等(2018b)发现不删除个体是有益的。为了产生后代，大多数算法随机初始化子网络，而Elsken等(2019)采用Lamarckian继承，即知识(以学习权重的形式)通过网络态射从父母网络传递给其子网络。Real等(2017)也让后代继承父母的所有突变不影响的参数;虽然这种继承不具有严格的函数不变性，但相比随机初始化也可以加速学习。此外，还允许改变学习速率，这可以被视为在NAS期间优化学习速率计划的方式。我们参考Stanleyet等(2019)最近对神经进化方法的深入研究。


Real等(2019)进行了比较RL、进化算法和随机搜索(RS)的研究，结论是RL和进化算法在最终测试精度方面平分秋色，随着时间的推移，进化算法具有更好的性能并且找到了更小的模型。实验中RL和进化算法始终表现优于RS，但具有相当小的余量：RS在CIFAR-10上大约$4 \%$的测试误差，而RL和进化算法大约$ 3.5 \%$(在“模型增强”之后，即增加了过滤器的深度和数量；实际对于搜索非增强空间差异约为 $2\%$)。Liu等(2018b)的差异甚至更小，他们报告RS的ImageNet在CIFAR-10的测试误差为$3.9\%$，和 top-1误差检验为$21.0\%$，而其进化算法分别是$3.75\%$和$20.3\%$。

*Bayesian 优化*(BO, 见,  (Shahriari等, 2016))是最常用的超参数优化方法之一(也可看这书的第一张)。但由于典型BO工具箱基于高斯过程且专注的是低维连续优化问题，因此大多数团队尚未将其应用于NAS。Swersky等(2013)和Kandasamy等(2018)推导出结构搜索空间的核函数，以便使用基于GP的BO算法。相比之下，一些研究使用基于树的模型(特别是, 树参数估计(Bergstra等, 2011), 或随机森林(Hutter等, 2011))可有效地搜索高维条件空间，并且在各种问题上表现出最先进的性能，这样的模型可同时优化神经结构和超参数(Bergstra等，2013；Domhan人，2015；Mendoza等，2016；Zela等，2018)。虽然缺乏完整的比较，但初步表明这些方法优于进化算法(Klein等，2018)。


Negrinho和Gordon(2017)和Wistuba(2017)开发了树结构的搜索空间并使用了*Monte-Carlo树搜索*。Elsken等(2017)提出了简单且性能良好的*登山*算法*hillclimbing*算法)，该算法通过贪心算法自动向更好的结构靠拢而不需要复杂的探索机制来找高效结构。


上述算法都采用离散搜索空间，而Liu等(2019b)提出了一种叫做*连续松弛(continuous relaxation)*的方法实现基于梯度的直接优化：将固定某个操作 $o_i$(e.g., 卷积或池化)在特定层去执行，改为从一组操作集$\{o_1, \dots, o_m \}$中计算凸组合。更具体地说，给定某层的输入$x$，则可计算输出$y$为
$$y  = \sum_{i=1}^{m} \alpha_i o_i(x), \alpha_i \ge 0, \sum_{i=1}^m \alpha_i = 1 ,$$ 其中凸系数$\alpha_i$可有效地使网络结构参数化。Liu等(2019b)通过对权重的训练数据和结构参数(如$\alpha$)的验证数据交替梯度下降的步骤来优化网络权重和结构。最后，通过对每层选取满足$ i^* =  {\arg\max}_i \,  \alpha_i$的操作$i^*$获得离散结构。Xie等(2019)和Cai等(2019)提出优化可能操作的参数化分布，而不是优化可能操作的权重$ \alpha $。Shin等(2018)和Ahmed\&Torresani(2018)也使用了基于梯度的神经结构优化，但是分别关注于优化层的超参数或连接方式。


## 性能评估策略


在上一部分中讨论的搜索策略目的是寻找最大化某些性能指标(如对看不见的数据的准确性)的神经结构$\mathsf{A}$。为了指导搜索过程，这些策略需要评估给定结构$\mathsf{A}$的性能。最简单的方法是在训练数据上训练$\mathsf{A}$并在验证数据上评估其性能。然而，依此训练每个要评估的结构经常会产生约数千GPU天的计算需求(Zoph\&Le, 2017; Real等, 2017; Zoph等, 2018; Real等, 2019)。
自然想到寻找加速性能评估的方法，下面讨论这些方法。


可以对完全训练后实际性能*较低保真*来估计性能(也表示为proxy度量)。这种降低保真的方式包含减少训练时间(Zoph等, 2018; Zela等,2018)、在数据子集训练(Klein等,2017b)、低分辨率的图片(Chrabaszcz等, 2017)或者减少每一层的过滤器和cell数量(Zoph等, 2018; Real等, 2019)。虽然降低保真近似可减少计算成本，但也会在评估中引入偏差，因为性能通常会被低估。只要搜索策略只与不同结构的排序有关而且排序相对稳定，偏差就不会影响结果。然而研究表明，当低保真评估与完全评估差异过大时排名会有很明显的变化 (Zela等, 2018)，并且认为随着保真减小排名变化逐渐变大(Li等, 2017; Falkne等, 2018)。

另一种方法是利用学习曲线外推来评估架构的性能(Swersky等, 2014; Domhan等, 2015; Klein等, 2017a; Baker等, 2017b; Rawal\&Miikkulainen, 2018)。Domhan等(2015)建议外推初始学习曲线并终止那些(预测)性能不佳的曲线从而加速结构搜索过程。Swersky et al. (2014),  Klein et al. (2017a),  Baker et al. (2017b) and Rawal and Miikkulainen (2018) 还考虑通过结构的超参数来预测哪些学习曲线可能得到最佳结构。Liu等(2018a)也提出训练一个预测新结构性能的替代模型，他不采用学习曲线外推法，而是基于结构/cell的属性预测性能，并外推到训练之外的结构/cell。预测神经结构性能的主要挑战是：为了加快搜索过程，需要在较少的评估基础上对更大搜索空间做出良好的预测。

另一种加速方法是基于已训练过的结构的权重来初始化新结构的权重。实现一种方法，被称为*网络态射*(Wei等, 2016)，保持代表网络的函数不变下允许修改结构，从而这种方法只需要很少的GPU天(Elsken等, 2017; Cai等, 2018a,b; Jin等, 2018)。这中方法允许不断增加网络容量的同时保持高性能而不用从头开始训练。对几个时段持续训练也可以通过网络态射利用额外容量。这类方法的一个优点是允许搜索空间在结构大小上没有固定上限 (Elsken等, 2017)；同时，严格网络态射只能使结构变的更大，而可能导致过于复杂的结构。当然可以通过允许缩小结构的近似网络态射来减少复杂(Elsken等, 2019)。


*“一次”(One-Shot)结构搜索*(见下图) 将所有结构视为超图(“一次”模型)的不同子图，并在同时包含此超图的结构边缘之间共享权重(Saxena\&Verbeek, 2016; Brock等, 2017; Pham等, 2018; Liu等, 2019b; Bender等, 2018; Cai等, 2019; Xie等, 2019)。只需要训练“一次”模型的权重(以所有方式的一种)，然后通过从“一次”模型中继承训练好的权重来评估结构(只是“一次”模型的子图)性能，而不需要对其他模型单独训练。这大大加快了结构性能评估，因为不需要训练(仅评估验证数据的性能)，故这种方法也仅需很少GPU天。因为严重低估最佳结构实际性能，“一次”模型通常会产生很大的偏差。虽然如此，但“一次”模型可对结构排序，故只需评估的性能与实际性能成正相关就足够。然而，目前尚不清楚是否是正相关 (Bender等, 2018; Sciuto等, 2019)。

![one_shot_vis](/one_shot_vis.jpg)
*“一次”结构搜索图示。
包含一个输入节点(记作0)，三个隐藏节点(记作1、2、3)和一个输出节点(记作4)的简单网络。“一次”模型(左)不是将单个操作(如3x3卷积)作用于节点，而是每个节点包含若干候选操作，即上图中的3x3卷积(红边)，5x5卷积(蓝边)和MaxPooling(绿边)。一旦训练了“一次”模型，其权重将在不同结构中共享，这些结构只是“一次”模型的子图(右)。*


不同“一次”NAS算法在训练“一次”模型的方式上有所不同：
ENAS(Pham等,2018)学习RNN控制器，该控制器从搜索空间中对结构进行采样，并通过强化获得的近似梯度训练“一次”模型。DARTS通过在“一次”模型边缘上放混合的候选操作来优化“一次”模型的权重并且使搜索空间连续松弛。SNAS(Xie等, 2019)不像DARTS那样优化操作的权重值，而是优化候选操作的分布。
作者采用具体分布(Maddison等, 2017; Jang等, 2017)和重新参数化(Kingma\&Welling, 2014)来松弛离散分布并使其可微分，进而通过梯度下降法实现优化。为了克服“一次”模型保留在GPU内存中的必要性，ProxylessNAS(Cai等,2019)对结构权重进行“binarizes”，每次操作包含一个边缘以外的所有边缘。然后通过对几个二进制结构进行采样并使用BinaryConnect(Courbariaux等,2015)更新相应的概率来学习边缘被包含(或不被包含)的概率。Bender等(2018)只对“一次”模型训练了一次，并表明训练期间通过路径丢失随机停止该模型的一部分已经足够。

虽然前面的方法训练期间优化了结构的分布，但是Bender等(2018)的方法可以被看作使用固定分布。后者获得的高性能表明，权重共享和(精心选取的)固定分布的组合可能是“一次”NAS的唯一必需成分。与这些方法相关的有超网络的meta-learning，它为新结构生成权重，因此只需要训练超网络而不是结构本身(Brock等,2017;Zhang等,2019)。他们的主要区别是权重不是严格共享的，而是由共享的(以采样结构为条件)超网络生成。

“一次”NAS的一般限制性是预定义的超图将搜索空间限制为其子图。此外，在结构搜索时要将整个超图保留在GPU存储器中导致限制了较小的超图和搜索空间，因此通常会与cell搜索空间结合使用。虽然权重共享NAS已经大大减少了计算资源(从上千到很少GPU天数)，但是如果结构的采样分布与“一次”模型一起优化而不是固定(Bender等, 2018)，目前还不好评价搜索带来的偏差。例如，探索搜索空间某些部分时的初始偏差可能会导致“一次”模型的权重更适合这些结构，这反过来会加强搜索对搜索空间这些部分的偏向。这可能导致NAS过早收敛或者结构的一次和真实性能的相关性很小(Sciuto等, 2019)。一般而言，对不同性能估计方法引入的偏差进行更系统分析将是未来工作的理想方向。


## 小结

大多数现有工作都集中在图像分类的NAS。一方面，这提供了一个具有挑战性的基准，因为许多手动工程专门用于寻找在该领域表现良好且不易被NAS超越的结构。另一方面，通过利用手工工程的知识来定义非常适合的搜索空间相对容易。反过来这使NAS不太可能找到远优于现有架构的新架构，因为找到的架构没有根本上区别。因此，我们认为通过将NAS应用于较少探索领域来超越图像分类问题非常重要。

[^footnote1]: 2个cell中每一个由5个block组成。对于每个block，由两个输入要选择并且每个输入都要选择应用于输入的操作，因此是$2 \cdot 5 \cdot 2 \cdot 2 = 40$维。注意，最初block内的求和或连接操作对应于另一个维度。然而本文实验中丢弃抛弃了这种选择，并且总对block内的输出求和。
[^footnote2]: 最近研究表明，只有梯度的高方差估计可用时，进化算法较基于梯度优化算法更有有竞争力(甚至是数百万个权重)，如对强化学习任务 (Salimans等, 2017; Such等, 2017; Chrabaszcz等,2018)。尽管如此，对于有监督的学习任务，基于梯度优化算法是目前最常用的算法。